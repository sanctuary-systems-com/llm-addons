name: "ramalama"
description: "GPU accelerated llama.cpp using Vulkan"
version: "1.0.0"
slug: "ramalama"
init: true
arch:
  - aarch64
  - amd64
  - armhf
  - armv7
  - i386
video: true
ports:
  10202/tcp: 10202
options:
  repository: "bartowski/Qwen2.5-7B-Instruct-GGUF"
  file: "Qwen2.5-7B-Instruct-Q4_K_M.gguf"
schema:
  repository: str
  file: str
#image: "ghcr.io/sanctuary-systems-com/{arch}-ramalama-vulkan"